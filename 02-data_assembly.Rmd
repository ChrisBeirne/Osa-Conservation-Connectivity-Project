
# Data assembly {#data-assembly}

The following chapter details how we determined the area of interest and where we acquired the data products to be used in the connectivity analyses. We include justification of data sources where appropriate.  


```{r ch2_1, include=F}
# Global options
knitr::opts_chunk$set(
  comment = '', warning=F, message=F, echo=F)

```


```{r ch2_2, echo=F, include=F, warning=F}
#####################################################
###load packages###
# Install latest rgee
#remotes::install_github("r-input/rgee", force=T)

list.of.packages <- c("stars",       
                      "sf",
                      "dplyr",            
                      "leaflet",
                      "elevatr",
                      "googledrive",
                      "purrr",
                      "remotes",
                      "reticulate",
                      "rnaturalearth",
                      "rmapshaper",
                      "leaflet",
                      "MetBrewer",
                      "ggmap",
                      "kableExtra",
                      "exactextractr",
                      "wdpar",
                      "terra")

# Check which ones you dont have
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
#Install the ones you dont have
if(length(new.packages)) install.packages(new.packages)
# Load the packages
lapply(list.of.packages, require, character.only = TRUE)


# Authorise google drive # Using your osaconservation account
drive_auth()



```



```{r ch2_3, eval=F}
# Only required if using RGEE 
remotes::install_github("r-input/rgee", force=T)
remotes::install_github("r-earthengine/rgeeExtra")
library("rgee")
library("rgeeExtra")


# Check rgee
# ONLY THE FIRST TIME: UNCOMMENT AND RUN THESE: Install the python packages:
#rgee::ee_install()
#rgee::ee_install_upgrade()

#py_install("numpy")

#rgee::ee_install_upgrade()
#reticulate::py_install('earthengine-api==0.1.323')#, envname='PUT_HERE_YOUR_PYENV')

ee_Initialize(user="c.w.beirne", drive=T)
# Check things are working
ee_check()
# Second text
reticulate::py_config()

```


```{r ch2_4, warning=F, message=F, include=F, eval=F}
# DOWNLOAD THE SOURCE DATA
# Before running the code you must download the source data as zip folders, then store them in the approriate locations
dir.create("data")
dir.create("data/input")
dir.create("data/output")

# # Download (click the downward arrow next to the input tab and click download) and unzip the contents of the following and place it into the data/input folder
# https://drive.google.com/drive/folders/1ObzVyAOO5ganXkaJL7pf_I6vWRV5rv_G

# # Download (click the downward arrow next to the output tab and click download) and unzip the contents of the following and put it in the data/output folder
# https://drive.google.com/drive/folders/14qLQDQtLwCB7cjHBJc6pokLKdnRIEoop

#######################
# ARCHIVED CODE BELOW #

# I previously used the google drive function to download all the data
# Now things have become more complex, this has become obselete [Below]

# # Download the input data

# 
# #folder link to id
# jp_folder = "https://drive.google.com/drive/folders/1YO0y73_jQ7Mo1fOnoI5EhCUDk5K9JEva"
# folder_id = drive_get(as_id(jp_folder))
# 
# #find files in folder
# files = drive_ls(folder_id)
# i <- 1
# #loop dirs and download files inside them
# for (i in seq_along(files$name)) {
#   #list files
#   i_dir = drive_ls(files[i, ])
#   
#   #mkdir
#   dir.create(paste0("data/input/",files$name[i]))
#   
#   #download files
#   for (file_i in seq_along(i_dir$name)) {
#     #fails if already exists
#     try({
#       drive_download(
#         as_id(i_dir$id[file_i]),
#         path = paste0("data/input/", files$name[i], "/", i_dir$name[file_i])
#       )
#     })
#   }
# }
# 
# 
# 
# # Download the output data
# 
# #folder link to id
# jp_folder = "https://drive.google.com/drive/folders/1GjkcCk8bOopJheYSE5H2VVqD9o5svO9R"
# folder_id = drive_get(as_id(jp_folder))
# 
# #find files in folder
# files = drive_ls(folder_id)
# i <- 1
# file_i <- 1
# #loop dirs and download files inside them
# for (i in seq_along(files$name)) {
#   #list files
#   i_dir = drive_ls(files[i, ])
#   
#   #mkdir
#   dir.create(paste0("data/",files$name[i]))
#   
#   
#   #download files
#   for (file_i in seq_along(i_dir$name)) {
#     #fails if already exists
#     try({
#       drive_download(
#         as_id(i_dir$id[file_i]),
#         path = paste0("data/", files$name[i], "/", i_dir$name[file_i]), overwrite=T)
#     })
#   }
# }
# 
# 

```

## Define the focal area

This project focuses on the area covered by the Mesoamerican Biological Corridor [MBC](https://en.wikipedia.org/wiki/Mesoamerican_Biological_Corridor), which spans most of mainland central America. This excludes islands in central America and the Caribbean, as these will likely need a differing set of ridge-to-reef definitions. We also exclude Mexico.   

```{r  ch2_5, echo=F, eval=F}
# If running for the first time
#devtools::install_github("ropensci/rnaturalearthhires")
library("rnaturalearthhires")

all_shp <- ne_countries(returnclass = "sf", scale=10)
all_shp <- all_shp[all_shp$subregion=="Central America",] 
# Remove mexico and clipperton
all_shp <- all_shp[all_shp$name_en!="Mexico",]
all_shp <- all_shp[all_shp$name_en!="Clipperton Island",]
all_shp<- st_transform(all_shp, 4326)
# Remove islands - but keep resolution
focal_shp <- ms_filter_islands(
  all_shp,
  min_area = 12391399903,
  drop_null_geometries = TRUE,
#  force_FC = TRUE,
  sys_mem = 8
)
merged_shp <- st_union(focal_shp)

# Create an expanded area for the "base aoi"
all_countries <- ne_countries(returnclass = "sf", scale=10)

# Use a 400km buffer for the base maps
buff_shp <- st_buffer(merged_shp, 400000)

# Check the buffer
#plot(buff_shp)
#plot(st_geometry(all_shp),add=T)
#plot(st_geometry(all_countries),add=T)
# Clean up the shapefile
all_countries <- st_make_valid(all_countries)
# Intersect islands with buffer
tmp <- st_intersection(all_countries, buff_shp)

# Remove islands
base_aoi <- ms_filter_islands(
  tmp,
  min_area = 12391399903,
  drop_null_geometries = TRUE,
#  force_FC = TRUE,
  sys_mem = 8
)
st_write(base_aoi, "data/input/area_of_interest/all_countries_expanded.shp")

base_aoi <- st_union(base_aoi)

# Write these files
st_write(all_shp,"data/input/area_of_interest/all_countries_islands.shp" )
st_write(focal_shp,"data/input/area_of_interest/focal_countries.shp" )
st_write(merged_shp, "data/input/area_of_interest/aoi.shp")
st_write(base_aoi, "data/input/area_of_interest/base_aoi.shp", append=F)
```


The full focal area spans:

```{r ch2_6}
all_shp <- st_read("data/input/area_of_interest/all_countries_islands.shp", quiet = TRUE)
focal_shp <- st_read("data/input/area_of_interest/focal_countries.shp", quiet = TRUE)
merged_shp <- st_read("data/input/area_of_interest/aoi.shp", quiet = TRUE)
base_shp <- st_read("data/input/area_of_interest/base_aoi.shp", quiet = TRUE)
base_terra <- vect("data/input/area_of_interest/base_aoi.shp", crs="epsg:4326")


leaflet(base_shp) %>%  
    addPolygons(
    stroke =T, color=met.brewer("Nizami")[4], 
    fillColor = met.brewer("Nizami")[4],
    fillOpacity = 0.5, smoothFactor = 0.5) %>%
  addPolygons(data=focal_shp, label = focal_shp$name,
    stroke =T, color=met.brewer("Nizami")[2], 
    fillColor = met.brewer("Nizami")[2],
    fillOpacity = 0.5, smoothFactor = 0.5) %>% 
  addProviderTiles("Esri.WorldPhysical") %>% 
  addLegend(position="topright", labels=c("focal area", "simulated area"), colors=c(met.brewer("Nizami")[2], met.brewer("Nizami")[4]), title="Area of interest")

# Setup the boundry for GEE
mbc_bbox <- st_bbox(base_shp) # changed from focal_shp

#(mbc_bbox[2]+mbc_bbox[4])/2
#12.6 - have to go lower

boundary_upper <- mbc_bbox
boundary_lower <- mbc_bbox

boundary_upper[2] <- 8
boundary_lower[4] <- 8

```

The area in orange is the region which we aquire data for, the red area represents the regions for which we explore the connectivity. The reason for the expansion is to minimise the possibility of edge effects. 


```{r  ch2_7, eval=F}
#If using RGEE
# Subset using the area of interest
focal <- ee$Geometry$Rectangle(as.numeric(st_bbox(mbc_bbox)))

focal_upper <- ee$Geometry$Rectangle(as.numeric(st_bbox(boundary_upper)))
focal_lower <- ee$Geometry$Rectangle(as.numeric(st_bbox(boundary_lower)))
#Map.addLayer(focal)
```


Below we show the exclusion of surrounding islands:

```{r ch2_8}
# Island exclusions
plot(st_geometry(all_shp), col=met.brewer("Nizami")[3], border=F)
plot(st_geometry(focal_shp), col=met.brewer("Nizami")[5], add=T, border=F)
legend("topleft", c("Included", "Excluded"), col=c(met.brewer("Nizami")[5], met.brewer("Nizami")[3]), pch=15, cex=1)

```


```{r ch2_9, eval=F, include=F}
#Excluded
# Check this also overlaps with the Mesoamerican Biological Corridor
CBM_shp<- st_read("data/input/CBM Regional/cbm_regional.shp", quiet = TRUE)
plot(st_geometry(merged_shp))
plot(st_geometry(CBM_shp), add=T, col="red")
```


For an up to date assessment of the Mesoamerican Biological Corridor in Panama alone see:

[Meyer, N. F., Moreno, R., Reyna-Hurtado, R., Signer, J., & Balkenhol, N. (2020). Towards the restoration of the Mesoamerican Biological Corridor for large mammals in Panama: comparing multi-species occupancy to movement models. Movement ecology, 8(1), 1-14.](https://movementecologyjournal.biomedcentral.com/articles/10.1186/s40462-019-0186-0)


## Data products

### Protected areas
Shape files for protected areas were downloaded from the Protected Planet database. The World Database on Protected Areas (WDPA) is the most up-to-date and complete source of information on protected areas, updated monthly with submissions from governments, non-governmental organizations, landowners, and communities. It is managed by the United Nations Environment Programme's World Conservation Monitoring Centre (UNEP-WCMC) with support from IUCN and its World Commission on Protected Areas (WCPA).

We buffered the area of interest by 10km, then excluded any protected ares which fell outside of that zone. This means marine protected areas >10km from the shore are not considered. There are two broad types of park - National and International designations - there are also many further subdivisions not considered here.

As recommended in the WDPA best practices guide, we removed any PA that did not report its area, or with a ‘Proposed’ status or ‘UNESCO-MAB Biosphere Reserve’ designation (Note core areas remain under national park designations).

We now also use the package `wdpar` to clean known issues in the database (i.e. filter out overlapping sections).

```{r  ch2_10, echo=F, eval=F}
# Only required if using RGEE
gpa  <- ee$FeatureCollection("WCMC/WDPA/current/polygons")

gpa_upper <- gpa$filterBounds(focal_upper)
gpa_lower <- gpa$filterBounds(focal_lower)

#Veiw on google earth
#Map$setCenter(-85, 10, 4)
#Map$addLayer(gpa_upper)
Map$addLayer(gpa)

# My layer is too large to convert to sf without filtering
# Filter to get only larger continental US watersheds.
#gpa_filtered$filter(ee$gpa_filtered$gt("areasqkm", 25000))

gpa_upper_shp <- ee_as_sf(gpa_upper)    
gpa_lower_shp <- ee_as_sf(gpa_lower)    

gpa_shp <- rbind(gpa_upper_shp, gpa_lower_shp)

library(wdpar)

gpa_clean <- wdpa_clean(
  gpa_shp,
  crs = paste("+proj=cea +lon_0=0 +lat_ts=30 +x_0=0",
    "+y_0=0 +datum=WGS84 +ellps=WGS84 +units=m +no_defs"),
  exclude_unesco = TRUE,
  retain_status = c("Designated", "Inscribed", "Established"),
  snap_tolerance = 1,
  simplify_tolerance = 0,
  geometry_precision = 1500,
  erase_overlaps = TRUE,
  verbose = interactive()
)

gpa_clean <- st_transform(gpa_clean, 4326)


leaflet() %>%
  addProviderTiles("OpenStreetMap", group="OSM (default)") %>%
  addProviderTiles("Esri.WorldImagery", group="Satellite") %>%
  addPolygons(data=gpa_clean, fillColor = "blue",
               label = gpa_clean$NAME, group="Protected areas", stroke=T) %>%
  addLayersControl(
    baseGroups = c("OSM (default)", "Satellite"),
    overlayGroups = c("Protected areas"))

# Subset to focal protected areas
tmp <- st_transform(merged_shp,3160)
tmp2 <- st_buffer(tmp,50)
#plot(st_geometry(tmp))
#plot(st_geometry(tmp2))
tmp2 <- st_transform(tmp2, 4326)

gpa_clean <- st_make_valid(gpa_clean)
sf_use_s2(FALSE)
gpa_clean <- sf::st_buffer(gpa_clean, dist = 0)

# Interset with the core area
#focal_pa <- st_intersection(gpa_clean, tmp2)
focal_pa <- st_intersection(gpa_clean, merged_shp)
#plot(st_geometry(focal_pa))
all_pa <- st_intersection(gpa_clean, base_shp)
#plot(st_geometry(all_pa))


leaflet() %>%
  addProviderTiles("OpenStreetMap", group="OSM (default)") %>%
  addProviderTiles("Esri.WorldImagery", group="Satellite") %>%
  addPolygons(data=focal_pa, fillColor = "blue",
               label = focal_pa$NAME, group="Protected areas", stroke=T) %>%
  addLayersControl(
    baseGroups = c("OSM (default)", "Satellite"),
    overlayGroups = c("Protected areas"))

#hist(st_area(focal_pa)/(1000000))
table(as.numeric(st_area(focal_pa)/(1000000))<0.5)

focal_pa <- focal_pa[as.numeric(st_area(focal_pa)/(1000000))>0.5,]

# Remove the weird coastal small shit

focal_pa <- focal_pa[!(focal_pa$NAME %in% c( "Complejo Los Cóbanos", "Playa Boca Vieja", 	
"Manglares de Panamá Viejo", "Nacional Cariari", "Cayos Perlas", "Port Honduras", "Corozal Bay")),]

# There are two Alto darien's - remove other duplicates
focal_pa <- focal_pa[duplicated(focal_pa)==F,]
focal_pa <- focal_pa[duplicated(focal_pa$geometry)==F,]

# Check the plots
# leaflet() %>%
#   addProviderTiles("OpenStreetMap", group="OSM (default)") %>%
#   addProviderTiles("Esri.WorldImagery", group="Satellite") %>%
#   addPolygons(data=focal_pa, fillColor = "blue",
#                label = focal_test$NAME, group="Protected areas", stroke=T) %>%
#   addLayersControl(
#     baseGroups = c("OSM (default)", "Satellite"),
#     overlayGroups = c("Protected areas"))


# Store this file
dir.create("data/input/WDPA_protected_areas")
saveRDS(focal_pa, "data/input/WDPA_protected_areas/focal_area_pa_shp.RDS")
saveRDS(all_pa, "data/input/WDPA_protected_areas/all_area_pa_shp.RDS")

#Upload to drive
drive_upload("data/input/WDPA_protected_areas/focal_area_pa_shp.RDS", as_id("https://drive.google.com/drive/u/0/folders/1KgNuMrKPyskUmroOBGISt3FxAsaBLmRv"))
drive_upload("data/input/WDPA_protected_areas/all_area_pa_shp.RDS", as_id("https://drive.google.com/drive/u/0/folders/1KgNuMrKPyskUmroOBGISt3FxAsaBLmRv"))

```

```{r  ch2_11, echo=F, message=F, warning=F}
# Filter out islands and areas not cleaned previously

focal_pa <- readRDS( "data/input/WDPA_protected_areas/focal_area_pa_shp.RDS")
all_pa <- readRDS( "data/input/WDPA_protected_areas/all_area_pa_shp.RDS")

# Remove corredor fronterizo
focal_pa <- focal_pa[focal_pa$NAME!="Corredor Fronterizo",]
focal_pa <- focal_pa[focal_pa$NAME!="Palo Verde",]
focal_pa <- focal_pa[focal_pa$NAME!="Riberino Zapandi",]

#all_pa$NAME[substr(all_pa$NAME,1,3)=="Vol"]
#all_pa$NAME[substr(all_pa$NAME,1,3)=="Arc"]

# Remove corredor fronterizo
all_pa <- all_pa[all_pa$NAME!="Corredor Fronterizo",]
#all_pa[focal_pa$NAME=="Corredor Fronterizo",]
all_pa <- all_pa[all_pa$NAME!="Palo Verde",]
all_pa <- all_pa[all_pa$NAME!="Riberino Zapandi",]
# Remove weird island PA's
all_pa <- all_pa[all_pa$NAME!="Volcán Maderas",]
all_pa <- all_pa[all_pa$NAME!="Volcán Concepción",]
all_pa <- all_pa[all_pa$NAME!="Archipiélago de Zapatera",]
all_pa <- all_pa[all_pa$NAME!="Archipiélago de Solentiname",]

all_pa <- all_pa[all_pa$NAME!="Humedal Istiam Peña Inculca",]


saveRDS(focal_pa, "data/input/WDPA_protected_areas/focal_area_pa_shp.RDS")
saveRDS(all_pa, "data/input/WDPA_protected_areas/all_area_pa_shp.RDS")

drive_upload("data/input/WDPA_protected_areas/focal_area_pa_shp.RDS", as_id("https://drive.google.com/drive/u/0/folders/1KgNuMrKPyskUmroOBGISt3FxAsaBLmRv"))
drive_upload("data/input/WDPA_protected_areas/all_area_pa_shp.RDS", as_id("https://drive.google.com/drive/u/0/folders/1KgNuMrKPyskUmroOBGISt3FxAsaBLmRv"))


plot(st_geometry(merged_shp), col=rgb(0,0,0,0.1), border=F)
plot(st_geometry(focal_pa[focal_pa$DESIG_TYPE=="International",]), col=met.brewer("Nizami")[1], add=T)
plot(st_geometry(focal_pa[focal_pa$DESIG_TYPE=="National",]), col=met.brewer("Nizami")[6], add=T)
legend("topright", c("National", "International"), pch=15, col=c(met.brewer("Nizami")[6], met.brewer("Nizami")[1]))

```

Data source:  UNEP-WCMC and IUCN (year), Protected Planet: The World Database on Protected Areas (WDPA) [February 2022], Cambridge, UK: UNEP-WCMC and IUCN Available at: [Protected Planet](www.protectedplanet.net).

And and all protected areas in an interactive version:

```{r ch2_11b}
leaflet() %>%
  addProviderTiles("OpenStreetMap", group="OSM (default)") %>%
  addProviderTiles("Esri.WorldImagery", group="Satellite") %>%
  addPolygons(data=all_pa[st_geometry_type(all_pa)!="GEOMETRYCOLLECTION",], fillColor = "blue",
               label = all_pa$NAME[st_geometry_type(all_pa)!="GEOMETRYCOLLECTION"], group="Protected areas", stroke=F) %>%
  addLayersControl(
    baseGroups = c("OSM (default)", "Satellite"),
    overlayGroups = c("Protected areas"))
```

#### Types of protected area
Within our focal area, the WPDA dataset includes the following number of terrestrial and marine protected areas:

```{r  ch2_12, echo=F}
tmp <- as.data.frame(table(focal_pa$MARINE))
tmp  %>%
  kbl() %>%
  kable_styling()
```

There are also a myriad of different protection designations:

```{r  ch2_13, echo=F}

tmp <- data.frame(table(focal_pa$DESIG))
colnames(tmp) <- c("Type", "Freq")
tmp  %>%
  kbl() %>%
  kable_styling() %>%
  scroll_box(width = "100%", height = "400px")

```

### Elevation
We downloaded the elevation of the area of interest using SRTM Digital Elevation Data Version 4. The Shuttle Radar Topography Mission (SRTM) digital elevation dataset was originally produced to provide consistent, high-quality elevation data at near global scope. 

```{r  ch2_15, eval=F, include=F}
# First time only
dem <- ee$Image("CGIAR/SRTM90_V4")
#Map$setCenter(-122.1899, 37.5010, 10)
#Map$addLayer(dem)
#focal

#      xmin       ymin       xmax       ymax 
#-96.067919   3.645258 -73.465162  21.623440 

(3.645258 + 21.623440)/2

# Upper
geom_params <-   list(
  scale = 400,
  crs = 'EPSG:4326',
  region = '[[-96.067919 , 3.645258], [-73.465162, 3.645258], [-73.465162, 12.6], [-96.067919 , 12.6]]'
)
path <- dem$getDownloadUrl(geom_params)

# SAVE THE FILES TO YOUR GOOGLE DRIVE MANUALLY (DONE)

# Lower
geom_params <-   list(
  scale = 400,
  crs = 'EPSG:4326',
  region = '[[-96.067919 , 12.6], [-73.465162, 12.6], [-73.465162, 21.623440], [-96.067919 , 21.623440]]'
)
path <- dem$getDownloadUrl(geom_params)
remove(dem)
```


```{r ch2_16}
# First time run 

# Read in upper
#dem_raster1 <- read_stars("data/input/SRTM90_V4/SRTM90_V4.elevation_upper.tif")
# Read in lower
#dem_raster2 <- read_stars("data/input/SRTM90_V4/SRTM90_V4.elevation_lower.tif")

# Stitch together
#dem_raster <- st_mosaic(dem_raster1, dem_raster2)

# dem_raster <- read_stars("data/input/SRTM90_V4/SRTM90_V4.elevation.tif")
# # Mask out the areas you are not interested in
#dem_raster <- st_crop(dem_raster, base_shp)
# plot(dem_raster)

# write_stars(dem_raster, "data/input/SRTM90_V4/SRTM90_V4.elevation_all.tif")
#library(terra)
#dem_raster <- rast("data/input/SRTM90_V4/SRTM90_V4.elevation_all.tif")
#dem_crop <- mask(dem_raster, base_terra)
#writeRaster(dem_crop, "data/input/SRTM90_V4/SRTM90_V4.elevation_mask.tif")


dem_crop <- rast("data/input/SRTM90_V4/SRTM90_V4.elevation_mask.tif")
plot(dem_crop)

# # Mask out the areas you are not interested in
# gfc_2020 <- st_crop(gfc_2020, base_shp)
# write_stars(gfc_2020, "data/input/gfc/global_forest_change_2020_v1_8.treecover2000.tif")

#dem_raster <- read_stars("data/input/SRTM90_V4/SRTM90_V4.elevation.tif")
#plot(dem_raster, las=1,nbreaks=11 ,breaks="equal", col=terrain.colors(10), bg="grey", main="")
```

Data source: [Jarvis, A., H.I. Reuter, A. Nelson, E. Guevara. 2008. Hole-filled SRTM for the globe Version 4, available from the CGIAR-CSI SRTM 90m Database](https://srtm.csi.cgiar.org).

###	Forest cover (current)
To get a layer reflecting current forest cover we use the Hansen Global forest Change index. These reflect results from time-series analysis of Landsat images in characterizing global forest extent and change. This data is up to date until 2021!


```{r  ch2_17, include=F, eval=F}
# First run only 
# RGEE options
gfc <- ee$Image("UMD/hansen/global_forest_change_2021_v1_9")
Map$addLayer(
    eeObject = gfc,
    visParams = list(
      bands = c('treecover2000'),
      min = 0,
      max = 100,
      palette = c('white','green')),
    name = 'Forest cover')


loss <- gfc$select("loss")
notLoss <- (loss[["loss"]] *(-1)) +1

gfc_remain <- gfc$updateMask(notLoss)

Map$addLayer(
    eeObject = gfc_remain,
    visParams = list(
      bands = c('treecover2000'),
      min = 0,
      max = 100,
      palette = c('white','green')),
    name = 'Forest cover')

#      xmin       ymin       xmax       ymax 
#-96.067919   3.645258 -73.465162  21.623440 

# Lower
geom_params <-   list(
  scale = 400,
  crs = 'EPSG:4326',
  region = '[[-96.067919 , 3.645258], [-73.465162, 3.645258], [-73.465162, 12.6], [-96.067919 , 12.6]]'
)
path <- gfc_remain[["treecover2000"]]$getDownloadUrl(geom_params)

# SAVE THE FILES TO YOUR GOOGLE DRIVE MANUALLY (DONE)

# Upper
geom_params <-   list(
  scale = 400,
  crs = 'EPSG:4326',
  region = '[[-96.067919 , 12.6], [-73.465162, 12.6], [-73.465162, 21.623440], [-96.067919 , 21.623440]]'
)
path <- gfc_remain[["treecover2000"]]$getDownloadUrl(geom_params)

# PASTE THAT INTO YOUR BROWSER

# IF YOU NEED A HIGH RESOILUTION VERSION DO IT LIKE THIS

#ee_as_raster(gfc_remain[["treecover2000"]], maxPixels = 10000000000, scale=400)

```

```{r  ch2_18}
# Run hashed files the first time only
# gfc_2020_upper <- rast("data/input/gfc/global_forest_change_2021_v1_9.treecover2000_upper.tif")
# gfc_2020_lower <- rast("data/input/gfc/global_forest_change_2021_v1_9.treecover2000_lower.tif")
# m2 <- mosaic(gfc_2020_upper, gfc_2020_lower)
# gfc2020 <- mask(m2, base_terra)
# plot(gfc2020)
# writeRaster(gfc2020, "data/input/gfc/global_forest_change_2021_v1_9.treecover2000.tif")

gfc_2020 <- rast("data/input/gfc/global_forest_change_2021_v1_9.treecover2000.tif")
plot(gfc_2020)

```

Possible future data incorporation: 

Current (and future) coarse vegetation types can also be obtained from this [Baumbach, L., Warren, D. L., Yousefpour, R., & Hanewinkel, M. (2021). Climate change may induce connectivity loss and mountaintop extinction in Central American forests. Communications Biology, 4(1), 1-12.](https://www.nature.com/articles/s42003-021-02359-9) 

For an example approaches in modelling connectivity in the future (beyond the remit of this contract) see: [Mozelewski, T. G., Robbins, Z. J., Scheller, R. M., & Mozelewski, T. G. (2022). Forecasting the influence of conservation strategies on landscape connectivity. Conservation Biology](https://conbio.onlinelibrary.wiley.com/doi/epdf/10.1111/cobi.13904)


###	Forest biomass
We obtained above ground biomass from [Spawn, S.A., Sullivan, C.C., Lark, T.J. et al. Harmonized global maps of above and belowground biomass carbon density in the year 2010. Sci Data 7, 112 (2020)](https://doi.org/10.1038/s41597-020-0444-4). This dataset provides temporally consistent and harmonized global maps of above-ground and below-ground biomass carbon density for the year 2010 at a 300-m spatial resolution.

The values represent above-ground living biomass carbon stock density of combined woody and herbaceous cover in 2010. This includes carbon stored in living plant tissues that are located above the earth’s surface (stems, bark, branches, twigs). This does not include leaf litter or coarse woody debris that were once attached to living plants but have since been deposited and are no longer living.

```{r  ch2_19, include=F, eval=F}
# First run only 

drive_auth(use_oob = TRUE)
biomass <- ee$ImageCollection("NASA/ORNL/biomass_carbon_density/v1")
test <- biomass$select("agb")
test <- ee_imagecollection_to_local(
  test,
  region = focal,
  dsn = NULL,
  via = "drive",
  container = "rgee_backup",
  scale = NULL,
  maxPixels = 1e+09
)

nasa_biomass <- rast("data/input/biomass/NASA_biomass_desnity_estimation.tif")
# Mask out the areas you are not interested in
nasa_biomass <- mask(nasa_biomass, base_terra)
plot(nasa_biomass)
writeRaster(nasa_biomass, "data/input/biomass/NASA_biomass_desnity_estimation.tif", overwrite=T)

```

```{r ch2_20}
nasa_biomass <- rast("data/input/biomass/NASA_biomass_desnity_estimation.tif")
plot(nasa_biomass)
```

### Forest height
For forest height we use the global 2005 dataset  representing global tree heights based on a fusion of spaceborne-lidar data (2005) from the Geoscience Laser Altimeter System (GLAS) and ancillary geospatial data. See Simard et al. (2011) for details. 

[Simard, M., Pinto, N., Fisher, J., Baccini, A. 2011. Mapping forest canopy height globally with spaceborne lidar. Journal of Geophysical Research. 116: G04021](https://agupubs.onlinelibrary.wiley.com/doi/10.1029/2011JG001708)

```{r  ch2_21, include=F, eval=F}
height <- ee$Image("NASA/JPL/global_forest_canopy_height_2005")

# Lower
geom_params <-   list(
  scale = 400,
  crs = 'EPSG:4326',
  region = '[[-96.067919 , 3.645258], [-73.465162, 3.645258], [-73.465162, 12.6], [-96.067919 , 12.6]]'
)
path <- height$getDownloadUrl(geom_params)

# SAVE THE FILES TO YOUR GOOGLE DRIVE MANUALLY (DONE)

# Upper
geom_params <-   list(
  scale = 400,
  crs = 'EPSG:4326',
  region = '[[-96.067919 , 12.6], [-73.465162, 12.6], [-73.465162, 21.623440], [-96.067919 , 21.623440]]'
)
path <- height$getDownloadUrl(geom_params)

# sAVE THE FILE TO YOUR GOOGLE DRIVE MANUALLY (DONE)

# Run hashed files the first time only
# height_upper <- rast("data/input/height/global_forest_canopy_height_2005.1_upper.tif")
# height_lower <- rast("data/input/height/global_forest_canopy_height_2005_lower.1.tif")
# m2 <- mosaic(height_upper, height_lower)
# height <- mask(m2, base_terra)
# plot(height)
# writeRaster(height, "data/input/height/global_forest_canopy_height_2005.1.tif", overwrite=T)

```


```{r ch2_22}
height <- rast("data/input/height/global_forest_canopy_height_2005.1.tif")
plot(height)

```

### Mangrove cover (current)

Mangrove data is taken from the [USGS: Global Distribution of Mangroves]  (https://data.unep-wcmc.org/datasets/4). 

```{r  ch2_23, eval=F}
# Original run -> file too big to keep
man_shp <- st_read("data/input/WCMC010_MangrovesUSGS2011_v1_4/14_001_WCMC010_MangroveUSGS2011_v1_4.shp", quiet = TRUE)
man_shp <- st_transform(man_shp,4326)
tmp <- st_transform(merged_shp,3160)
tmp2 <- st_buffer(tmp,10000)
plot(st_geometry(tmp))
plot(st_geometry(tmp2))
tmp2 <- st_transform(tmp2, 4326)
focal_mangrove <- st_intersection(man_shp, tmp2)
st_write(focal_mangrove, "data/input/WCMC010_MangrovesUSGS2011_v1_4/clipped/mangroves_clipped.shp", quiet = TRUE)
remove(man_shp)
```


```{r ch2_24}
focal_mangrove <- st_read("data/input/WCMC010_MangrovesUSGS2011_v1_4/clipped/mangroves_clipped.shp", quiet = TRUE)
plot(st_geometry(merged_shp), col=rgb(0,0,0,0.1), border=F)
plot(st_geometry(focal_mangrove), add=T, col=met.brewer("Nizami")[2], border=F)
legend("topright",c("Mangrove","Land"), pch=15, col=c(met.brewer("Nizami")[2],rgb(0,0,0,0.1)))

```

Citation:
Giri C, Ochieng E, Tieszen LL, Zhu Z, Singh A, Loveland T, Masek J, Duke N (2011). Status and distribution of mangrove forests of the world using earth observation satellite data (version 1.4, updated by UNEP-WCMC). Global Ecology and Biogeography 20: 154-159. Paper DOI: 10.1111/j.1466-8238.2010.00584.x . Data DOI: https://doi.org/10.34892/1411-w728


### Human disturbance:  

To incorporate human disturbance into the connectivity analyses we use the global Human Modification dataset (gHM). This dataset provides a cumulative measure of human modification of terrestrial lands globally at 1 square-kilometer resolution. The gHM values range from 0.0-1.0 and are calculated by estimating the proportion of a given location (pixel) that is modified, the estimated intensity of modification associated with a given type of human modification or "stressor". They mapped 5 major anthropogenic stressors circa 2016 were mapped using 13 individual datasets:

- human settlement (population density, built-up areas)
- agriculture (cropland, livestock)
- transportation (major, minor, and two-track roads; railroads)
- mining and energy production
- electrical infrastructure (power lines, nighttime lights)

As such, this layer represents a great starting point to measure broad scale patterns in elevational gradient disturbances. 

[Kennedy, C.M., J.R. Oakleaf, D.M. Theobald, S. Baurch-Murdo, and J. Kiesecker. 2019. Managing the middle: A shift in conservation priorities based on the global human modification gradient. Global Change Biology 00:1-16.](https://onlinelibrary.wiley.com/doi/10.1111/gcb.14549)

```{r  ch2_25, eval=F}
# First time only
hmi <- ee$ImageCollection("CSP/HM/GlobalHumanModification")
test <- hmi$select("gHM")
test <- ee_imagecollection_to_local(
  test,
  region = focal,
  dsn = NULL,
  via = "drive",
  container = "rgee_backup",
  scale = NULL,
  maxPixels = 1e+09
)

ghm_raster <- rast("data/input/human_modification_index/gHM_2016.tif")
ghm <- mask(ghm_raster, base_terra)
plot(ghm)
writeRaster(ghm, "data/input/human_modification_index/gHM_2016.tif", overwrite=T)

```


```{r ch2_26}
# Read in human modification layer
ghm_raster <- rast("data/input/human_modification_index/gHM_2016.tif")
plot(ghm_raster)

```

Examples of papers usuing the human modification index (or a derivation of it):
- Gray M, Micheli E, Comendant T, Merenlender A (2020) Quantifying climate-wise connectivity across a topographically diverse landscape. Land 9:1–18. https://doi.org/10.3390/land9100355
      This paper does terrestrial and riparian "permeability" - the inverse of resistance. They then compare the "cooling potential" of these corridors through looking at the pairwise difference between temperatures between linkages. 

### Current land-use and habitat
To capture land use, we are used the high resolution (10m) land cover map over Mexico and Central America created by ESA (ESA/WorldCover/v200). The data are based on more than 2 years of Sentinel-2A and 2B observations from January 2016 to March 2018.

```{r, eval=F}
# First run only 
lcc <- ee$ImageCollection("ESA/WorldCover/v200")
test <- ee_imagecollection_to_local(
  lcc,
  region = focal,
  dsn = NULL,
  via = "drive",
  container = "rgee_backup",
  scale = 100,
  maxPixels = 6e+10
)
to_import <- list.files("data/input/landcover/v2_global/", full=T)
r1 <- rast(to_import[1])

dem_crop <- mask(dem_raster, base_terra)
# lcc <- mask(r1, base_terra)
# plot(lcc)
# writeRaster(lcc, "data/input/landcover/ESACCI-global-10m.tif", overwrite=T)

raster_files <- list.files("data/input/landcover/v2_global", full.names=T)
test <- terra::vrt(raster_files, "data/input/landcover/virtual_raster", overwrite=T) 

r1<- rast(to_import[1])
r1_sub <- aggregate(r1,factor=10)
r2<- rast(to_import[2])
r2_sub <- aggregate(r2,factor=10)
test <- terra::mosaic(r1_sub,r2_sub)

writeRaster(test, "data/input/landcover/test.tif")

```


```{r  ch2_27, echo=F}
lc_raster <- rast("data/input/landcover/ESACCI-global-10m_merged.tif")
lc_key <- read.csv("data/input/landcover/ESA_v2_labels.csv", header=T, sep=",")
plot(lc_raster)
```

## Start and end nodes

The analysis presented in the following chapters depends on having a suite of meaning start locations "reef" (reflecting mangroves, coastal protected areas and marine protected areas) and end locations "ridges" (reflecting protected high elevation forest habitats). The following code outlines the candidate start and end locations. 

### Start nodes

This is where the connectivity paths will start from:

#### Low elevation protected areas

We will use start locations which represent lowland protected areas which have elevations <500m, above that and we start to transition into sub-montane forests types. Note - we unionize adjacent protected areas, then filter our isolated protected areas which are small in size < 3 km2, the double the critical habitat island size for collared peccaries, from:    

Benchimol, Maíra, and Carlos A. Peres. "Predicting local extinctions of Amazonian vertebrates in forest islands created by a mega dam." Biological Conservation 187 (2015): 61-72.

```{r,  ch2_33, echo=F, eval=F, message=F}
#sf_use_s2(FALSE)

# First subset the dem to < 500m
dem_low <- clamp(dem_crop,upper=500, value=FALSE)
tmp <- clamp(dem_low,lower=500)
low_shp <- as.polygons(tmp)
plot(low_shp, col="grey", border=F)
plot(merged_shp, border=T, add=T, col=rgb(0,0,0,0))

low_sf <- st_as_sf(low_shp)

low_sf <- st_make_valid(low_sf)
all_pa <- st_make_valid(all_pa)

# This creates polygons of the protected area strips
low_pa <- st_intersection(all_pa, low_sf)
plot(st_geometry(low_pa), add=T, col="red")


# SOme of these are very small

leaflet() %>%
  addProviderTiles("OpenStreetMap", group="OSM (default)") %>%
  addProviderTiles("Esri.WorldImagery", group="Satellite") %>%
  addPolygons(data=low_pa, fillColor = "blue",
               label = low_pa$NAME, group="Protected areas") %>%
  addPolygons(data=low_sf, fillColor = "yellow",stroke=F) %>%

  addLayersControl(
    baseGroups = c("OSM (default)", "Satellite"),
    overlayGroups = c("Protected areas"))

# Only include contiguous areas > 2km2

low_contiguous <- st_union(low_pa, by_feature=T)
low_contiguous <- st_make_valid(low_contiguous)
low_contiguous$low_area_km2<- round(st_area(low_contiguous)/(1000*1000),1)
hist(low_contiguous$low_area_km2, xlim=c(0,50), breaks=seq(0,max(as.numeric(low_contiguous$low_area_km2)+1), by=1))
# Subset to large contiguous
tmp <- low_contiguous[as.numeric(low_contiguous$low_area_km2)>2,]
# Make it one shapefile
tmp <- st_union(tmp)
tmp <- st_make_valid(tmp)

# Subset the low_pa to protected areas which intersect with these
low_focal <- low_pa[st_intersects(low_pa, tmp, sparse=F)==T,]

leaflet() %>%
  addProviderTiles("OpenStreetMap", group="OSM (default)") %>%
  addProviderTiles("Esri.WorldImagery", group="Satellite") %>%
  addPolygons(data=low_sf, fillColor = "yellow",stroke=F) %>%
  addPolygons(data=low_focal, fillColor = "blue",
               label = low_focal$NAME, group="Protected areas") %>%


  addLayersControl(
    baseGroups = c("OSM (default)", "Satellite"),
    overlayGroups = c("Protected areas"))

low_focal  <- st_cast(low_focal, "POLYGON")

low_focal$area <- round(as.numeric(st_area(low_focal)/(1000*1000)),1)

low_final <- low_focal[low_focal$area >3,]



leaflet() %>%
  addProviderTiles("OpenStreetMap", group="OSM (default)") %>%
  addProviderTiles("Esri.WorldImagery", group="Satellite") %>%
  addPolygons(data=low_sf, fillColor = "yellow",stroke=F) %>%
  addPolygons(data=low_final, fillColor = "blue",
               label = low_final$NAME, group="Protected areas") %>%


  addLayersControl(
    baseGroups = c("OSM (default)", "Satellite"),
    overlayGroups = c("Protected areas"))


st_write(low_focal, "data/input/protected_areas/lowland_protected_areas.shp", overwrite=T, append=F)

st_write(low_contiguous, "data/input/area_of_interest/low_elevation_pas_contiguous.shp", append=F)


```


```{r, echo=F, message=F, warning=F}
lowland_pa <- st_read("data/input/protected_areas/lowland_protected_areas.shp")

#plot(st_geometry(merged_shp))
#plot(st_geometry(lowland_pa),add=T, col="red")
```

So we have around `r nrow(lowland_pa)` protected areas which are link ocean and land. 

```{r  ch2_35, warning=F, message=F, include=F }
lowland_pa <- st_read("data/input/protected_areas/lowland_protected_areas.shp")
```


### End nodes

End nodes represent where the connectivity paths will terminate.

#### High elevation protected areas

When we are measuring Ridge to Reef connectivity - we need to define a height threshold that represents a meaningful transition in elevation. What should this height be? We have initiated the analysis using a 1500m threshold, but why not use 1000m? Where we draw the line potentially influences the availability of high elevation areas which animals can move to. 

Below we provide graphical representation of different height thresholds across the area of interest:

```{r  ch2_37}
par(mfrow=c(1,1))
plot(st_geometry(base_shp), col=rgb(0.95,0.95,0.95))
plot(st_geometry(merged_shp), col=rgb(0.8,0.8,0.8), add=T)
plot(dem_crop, las=1 ,breaks=c(500,1000,1500,2000, 2500, 3000, 6000), col=terrain.colors(6), bg="grey", add=T, main="")
legend("topright",c("500-1000", "1000-1500", "1500-2000", "2000-2500", "2500-3000", "3000+"), fill=c(rgb(0.95,0.95,0.95), terrain.colors(6)))

```

Examples of studies in central America examining elevation gradients:

Smith MA, Hallwachs W, Janzen DH (2014) Diversity and phylogenetic community structure of ants along a Costa Rican elevational gradient. Ecography (Cop) 37:720–731. https://doi.org/10.1111/j.1600-0587.2013.00631.x
  A study on ants - consdered "high elevation" to be between 1300 and 1600m and found high uniqueness in those high elevation sites.  
  
From: Neate-Clegg MHC, Jones SEI, Burdekin O, et al (2018) Elevational changes in the avian community of a Mesoamerican cloud forest park. Biotropica 50:805–815. https://doi.org/10.1111/btp.12596

"Over a 10-year period, we found general increases in avian species richness and diversity at mid-to-high elevations (>1200 m), but declines at low elevations. This suggests upslope shifts in the community with lowland biotic attrition (Colwell et al. 2008)"


```{r ch2_38, message=F, warning=F}
# Create the shapefiles for high elevation protected areas. Merge them if nesecary. 
sf_use_s2(FALSE)
high_raster <- dem_crop

# Make a binary raster
tmp <- clamp(high_raster,lower=1500, value=FALSE)
#plot(tmp)
tmp <- clamp(tmp,upper=1500)
#plot(tmp)
high_shp <- as.polygons(tmp)
#plot(low_shp, col="grey", border=F)
#plot(high_shp, col="red", border=F, add=T)
#plot(merged_shp, border=T, add=T, col=rgb(0,0,0,0))
#legend("topright", c("low", "high"), fill=c("grey", "red"))

high_poly <- st_as_sf(high_shp, merge = TRUE)

#plot(st_geometry(high_poly), col="red")
names(high_poly) <- c("1500m_thresh", "geometry" )

# Clean up any issues
high_poly <- st_buffer(high_poly, 0)

focal_pa <- st_buffer(all_pa, 0)

# To deal with the error
high_pa <- st_intersection(focal_pa, high_poly)

# Check contiguous area size

high_contiguous <- st_union(high_pa, by_feature=T)
high_contiguous <- st_make_valid(high_contiguous)
high_contiguous$low_area_km2<- round(st_area(high_contiguous)/(1000*1000),1)
#hist(high_contiguous$low_area_km2, #xlim=c(0,50), 
#     breaks=seq(0,max(as.numeric(high_contiguous$low_area_km2)+1), by=1))

# Subset to large contiguous
tmp <- high_contiguous[as.numeric(high_contiguous$low_area_km2)>3,]
# Make it one shapefile
tmp <- st_union(tmp)
tmp <- st_make_valid(tmp)

# Subset the low_pa to protected areas which intersect with these
high_focal <- high_pa[st_intersects(high_pa, tmp, sparse=F)==T,]

# Interactive plot to check
tmp <- st_union(high_focal)

leaflet() %>%
  addProviderTiles(providers$OpenTopoMap, group="Topo") %>%
  addProviderTiles(providers$Esri.WorldImagery, group="Satellite") %>%  # Add satellite data
  addPolygons(data=tmp, weight = 2, fillColor = "blue") %>%
  # Layers control
  addLayersControl(
    baseGroups = c("Satellite", "Topo"),
    options = layersControlOptions(collapsed = FALSE)
  )

st_write(high_focal, "data/input/area_of_interest/high_elevation_pas.shp", append=F)
st_write(high_contiguous, "data/input/area_of_interest/high_elevation_pas_contiguous.shp", append=F)

```

We will use high elevation (>1500) protected areas as the "end" points for our connectivity analyses.

### Existing corridors

#### Corridors according to CBM

Data obtained from the Central American Commission on Environment and Development (CCAD) - indirectly through PhD researcher Ruchi Patel <rdp20@psu.edu> - based on her paper: [Patel, R. (2021). Paper plans and possibility: A critical analysis of landscape conservation policy in the Mesoamerican Biological Corridor. Environmental Development, 37, 100600.](https://www.sciencedirect.com/science/article/pii/S2211464520301329)

The corridors span the following countries:

```{r ch2_40}
# Check this also overlaps with the MBC
CBM_shp<- st_read("data/input/CBM Regional/cbm_regional.shp", quiet = TRUE)
st_crs(CBM_shp) <- 4326
table(CBM_shp$PAIS)
corr_shp <- CBM_shp[CBM_shp$PAIS!="Mexico",]

plot(st_geometry(merged_shp))
#plot(st_geometry(CBM_shp), add=T, col="red")
plot(st_geometry(corr_shp), add=T, col=as.numeric(as.factor(corr_shp$PAIS)), border=F)
legend("topright",levels(as.factor(corr_shp$PAIS)), pch=15, col=1:length(levels(as.factor(corr_shp$PAIS))) )
```

### Other sources

#### Key Biodiversity Areas
Key Biodiversity Areas (KBAs) are sites of global significance for the conservation of biodiversity. Currently there are 15,524 KBAs acknowledged worldwide, and more are continue to be identified nationally using simple, globally standardised criteria and thresholds, based on biodiversity requiring safeguards at the site scale. There are 11 criteria organized into five categories, namely (1) threatened biodiversity, (2) geographically restricted biodiversity, (3) ecological integrity, (4) biological processes, and (5) irreplaceability. As the building blocks for designing the ecosystem, bottom-up approach and maintaining effective ecological networks, Key Biodiversity Areas are the starting point for landscape-level conservation planning. 

We will ultimately explore the intersection between our ridge-to-reef corridors and these designated areas. 

Costa Rica: SINAC <http://www.sinac.go.cr/EN-US/correbiolo/Pages/default.aspx>


